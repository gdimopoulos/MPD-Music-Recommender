{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import mpd\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "MPD_SRV = '192.168.1.111'\n",
    "MPD_PORT = 6600\n",
    "BEETS_DB = \"./musiclibrary.blb\"#careful of the extension, default is .blb but can be changed in beets conf\n",
    "SHUFFLE = True\n",
    "RECOMMENDATIONS = 20\n",
    "RND_SEED = True\n",
    "\n",
    "conn = sqlite3.connect(BEETS_DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 'items' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the desired columns from the table into a DF\n",
    "df_items = pd.read_sql_query(\"select id, title, artist, length, year, album, genre, grouping, path from items;\", conn)\n",
    "# cast path type to str\n",
    "df_items['path'] = df_items['path'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 'item_attributes' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire 'item_attributes' to a DF\n",
    "df_attr = pd.read_sql_query(\"select id, entity_id, key, value from item_attributes;\", conn)\n",
    "\n",
    "# pivot columns to rows\n",
    "pivot = df_attr.pivot(index='entity_id', columns='key', values='value')\n",
    "\n",
    "# create column 'id' to merge\n",
    "pivot['id'] = pivot.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the 2 tables on 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two df on 'id' column\n",
    "df_item_attr = pd.merge(df_items, pivot, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.heatmap(df_item_attr.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "\n",
    "##df_item_attr.dropna(inplace=True) do this to drop rows with missing values (too many right now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excludes = ['id','title','artist','album','length','year','data','soup','path','data_source']\n",
    "keys = [str(key) for key in df_item_attr.keys().values if key not in excludes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the soup of keywords used for the similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join([str(x[key]) for key in keys])\n",
    "\n",
    "df_item_attr['soup'] = df_item_attr.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer and create the count matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df_item_attr['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Cosine Similarity matrix based on the count_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of your main DataFrame and construct reverse mapping as before\n",
    "df_items = df_items.reset_index()\n",
    "indices = pd.Series(df_items.index, index=df_items['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(seed, recommendations, cosine_sim=cosine_sim2):\n",
    "\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[seed]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the <length> most similar tracks\n",
    "    sim_scores = sim_scores[1:recommendations+1]\n",
    "\n",
    "    # Get the track indices\n",
    "    track_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    return track_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Either select a seed song manually or make a random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RND_SEED:\n",
    "    seed = random.choice(df_items['id'])\n",
    "else:\n",
    "    seed = 78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "recommendation_indices = get_recommendations(seed, RECOMMENDATIONS, cosine_sim2)\n",
    "\n",
    "seed_item = df_items[df_items['id']==seed]\n",
    "\n",
    "print \"Getting the top {} most similar tracks for song\".format(RECOMMENDATIONS)\n",
    "print \"{} by {}\\n\".format((seed_item['title'].iloc[0]).encode('utf-8'),(seed_item['artist'].iloc[0]).encode('utf-8'))\n",
    "\n",
    "if SHUFFLE:\n",
    "    random.shuffle(recommendation_indices)\n",
    "    \n",
    "for c, index in enumerate(recommendation_indices):\n",
    "    print \"{}.\\t{} - {}\".format(c+1, (df_items['title'].iloc[index]).encode('utf-8'), (df_items['artist'].iloc[index]).encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mpd.MPDClient()\n",
    "\n",
    "try:\n",
    "    client.connect(MPD_SRV, MPD_PORT)\n",
    "except socket.error:\n",
    "    print \"couldn't connect to mpd server.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.clear()\n",
    "for index in recommendation_indices:\n",
    "    try:\n",
    "        path = df_items['path'].iloc[index]\n",
    "        path = path.replace('/media','USB')\n",
    "        client.addid(path)\n",
    "    except mpd.CommandError, cer:\n",
    "        print cer\n",
    "        print \"failed to ad {}\".format(path)\n",
    "        pass\n",
    "client.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
